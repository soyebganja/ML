# -*- coding: utf-8 -*-
"""11.8:Hyperparameter Tuning: GridsearchCV.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVdWFXavScihHiKSf_kBfQek1AgtbqBN
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

X, y = make_classification(
    n_samples=1000,
    n_features=10,
    n_informative=8,
    n_redundant=2,
    n_repeated=0,
    n_classes=2,
    random_state=42
)

"""### Method 1: Evaluate the model using train, test split and tune parameters by trail and error"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# split data into train and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

model = DecisionTreeClassifier(criterion="gini", max_depth=10)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))

"""Method 2: Evaluate the model using Cross_Val_Score"""

from sklearn.model_selection import cross_val_score

scores = cross_val_score(DecisionTreeClassifier(criterion="gini", max_depth=5), X, y, cv=5)
scores

scores = cross_val_score(DecisionTreeClassifier(criterion="gini", max_depth=10), X, y, cv=5)
scores

scores = cross_val_score(DecisionTreeClassifier(criterion="entropy", max_depth=5), X, y, cv=5)
scores

scores = cross_val_score(DecisionTreeClassifier(criterion="entropy", max_depth=10), X, y, cv=5)
scores

criterion = ["entropy", "gini"]
max_depth = [5, 10, 15]

arg_scores = {}

for c in criterion:
    for d in max_depth:
        scores_list = cross_val_score(DecisionTreeClassifier(criterion=c, max_depth=d), X, y, cv=5)
        arg_scores[c + "_" + str(d)] = np.average(scores_list)
        # print(c, d, np.average(scores_list))

arg_scores

from sklearn.model_selection import GridSearchCV

param_grid = {
    "criterion": ["gini", "entropy"],
    "max_depth": [5, 10, 15]
}

grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5, return_train_score=False)
grid_search.fit(X, y)

grid_search.cv_results_

df = pd.DataFrame(grid_search.cv_results_)
df

df[["param_criterion", "param_max_depth", "mean_test_score"]]

grid_search.best_params_

grid_search.best_estimator_

from sklearn import svm

model_params = {
    "decision_tree": {
        "model": DecisionTreeClassifier(),
        "params": {
            "criterion": ["gini", "entropy"],
            "max_depth": [5, 10, 15]
        }
    },
    "svm": {
        "model": svm.SVC(gamma="auto"),
        "params": {
            "C": [1, 10, 20],
            "kernel": ["rbf", "linear"]
        }
    }
}

scores = []

for model_name, mp in model_params.items():
    grid_search = GridSearchCV(mp["model"], mp["params"], cv=5, return_train_score=False)
    grid_search.fit(X, y)
    scores.append({
        "model": model_name,
        "best_score": grid_search.best_score_,
        "best_params": grid_search.best_params_
    })

scores

pd.DataFrame(scores)

